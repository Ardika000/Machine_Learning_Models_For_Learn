{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac275527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from os.path import join, normpath\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3c76e",
   "metadata": {},
   "source": [
    "### Requirement Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2abda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Fixed Variabels\n",
    "RANDOM_STATE = 26\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "MIX_CSV_PATH = \"../data/HLS-CMDS/Mix.csv\"\n",
    "MIX_AUDIO_PATH = \"../data/HLS-CMDS/Mix/Mix\"\n",
    "LS_CSV_PATH = \"../data/HLS-CMDS/LS.csv\"\n",
    "LS_AUDIO_PATH = \"../data/HLS-CMDS/LS/LS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9996c8d9",
   "metadata": {},
   "source": [
    "## Mix Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0532ac",
   "metadata": {},
   "source": [
    "##### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "372e3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best parameters: {'svc__C': 1, 'svc__gamma': 0.001, 'svc__kernel': 'linear'}\n",
      "Mix: Gender -> macro-F1: 0.5445134575569358\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.54      0.59      0.57        22\n",
      "           M       0.55      0.50      0.52        22\n",
      "\n",
      "    accuracy                           0.55        44\n",
      "   macro avg       0.55      0.55      0.54        44\n",
      "weighted avg       0.55      0.55      0.54        44\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13  9]\n",
      " [11 11]]\n"
     ]
    }
   ],
   "source": [
    "df_gender_mix = pd.read_csv(MIX_CSV_PATH)\n",
    "N_MFCC_GENDER_MIX = 45\n",
    "\n",
    "df_gender_mix['audio_path'] = df_gender_mix['Mixed Sound ID'].apply(lambda x: normpath(join(MIX_AUDIO_PATH, f\"{str(x).strip()}.wav\").replace('\\\\', '/')))\n",
    "\n",
    "def extract_mfcc_gender_mix(filename, n_mfcc=N_MFCC_GENDER_MIX):\n",
    "    y, sr = librosa.load(filename, sr=44100)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    return np.concatenate([mfcc_mean, mfcc_std])\n",
    "\n",
    "# def flatten_mfcc(mfcc):\n",
    "#     return np.array(mfcc).flatten()\n",
    "\n",
    "mfcc_list_gender_mix = []\n",
    "labels_gender_mix = []\n",
    "\n",
    "for _, row in df_gender_mix.iterrows():\n",
    "    try:\n",
    "        mfcc_gender_mix = extract_mfcc_gender_mix(row['audio_path'])\n",
    "        # mfcc_flat = flatten_mfcc(mfcc)\n",
    "        mfcc_list_gender_mix.append(mfcc_gender_mix)\n",
    "        labels_gender_mix.append(row['Gender'])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed: {row['audio_path']} -> {e}\")\n",
    "    \n",
    "X_gender_mix = pd.DataFrame(mfcc_list_gender_mix)\n",
    "y_gender_mix = pd.Series(labels_gender_mix)\n",
    "\n",
    "Xtrain_gender_mix, Xtest_gender_mix, ytrain_gender_mix, ytest_gender_mix = train_test_split(X_gender_mix, y_gender_mix, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_gender_mix)\n",
    "\n",
    "pipe_model_gender_mix = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(kernel='rbf', random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid_gender_mix = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "model_grid_gender_mix = GridSearchCV(\n",
    "    estimator=pipe_model_gender_mix, \n",
    "    param_grid=param_grid_gender_mix, \n",
    "    scoring='f1_macro', \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model_grid_gender_mix.fit(Xtrain_gender_mix, ytrain_gender_mix)\n",
    "model_gender_mix = model_grid_gender_mix.best_estimator_\n",
    "print(f\"Best parameters: {model_grid_gender_mix.best_params_}\")\n",
    "\n",
    "ypred_gender_mix = model_gender_mix.predict(Xtest_gender_mix)\n",
    "f1_gender_mix = f1_score(ytest_gender_mix, ypred_gender_mix, average='macro')\n",
    "print(f\"Mix: Gender -> macro-F1: {f1_gender_mix}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ytest_gender_mix, ypred_gender_mix))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ytest_gender_mix, ypred_gender_mix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5416373",
   "metadata": {},
   "source": [
    "##### Heart Sound Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "Best parameters: {'svc__C': 0.1, 'svc__gamma': 0.001, 'svc__kernel': 'linear'}\n",
      "Mix: Heart Sound Type -> macro-F1: 0.537100122100122\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             AV Block       0.67      0.50      0.57         4\n",
      "  Atrial Fibrillation       0.00      0.00      0.00         4\n",
      "Early Systolic Murmur       0.50      1.00      0.67         4\n",
      "Late Diastolic Murmur       0.75      0.75      0.75         4\n",
      " Late Systolic Murmur       0.62      1.00      0.77         5\n",
      "  Mid Systolic Murmur       0.50      0.25      0.33         4\n",
      "               Normal       1.00      0.25      0.40         4\n",
      "                   S3       1.00      0.80      0.89         5\n",
      "                   S4       0.62      1.00      0.77         5\n",
      "          Tachycardia       0.25      0.20      0.22         5\n",
      "\n",
      "             accuracy                           0.59        44\n",
      "            macro avg       0.59      0.57      0.54        44\n",
      "         weighted avg       0.59      0.59      0.55        44\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2 1 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 1 0 0 0 0 2 0]\n",
      " [0 0 4 0 0 0 0 0 0 0]\n",
      " [0 1 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0]\n",
      " [1 0 0 0 1 1 0 0 0 1]\n",
      " [0 0 0 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 5 0]\n",
      " [0 0 2 0 1 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "N_MFCC_HEARTSOUNDTYPE = 65\n",
    "df_heartsoundtype_mix = pd.read_csv(MIX_CSV_PATH)\n",
    "\n",
    "df_heartsoundtype_mix['audio_path'] = df_heartsoundtype_mix['Mixed Sound ID'].apply(lambda x: normpath(join(MIX_AUDIO_PATH, f\"{str(x).strip()}.wav\").replace('\\\\', '/')))\n",
    "\n",
    "def extract_mfcc(filename, n_mfcc=N_MFCC_HEARTSOUNDTYPE):\n",
    "    y, sr = librosa.load(filename, sr=2000)  # â†“ better for heart sounds\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "    features = np.concatenate([\n",
    "        np.mean(mfcc, axis=1),\n",
    "        np.std(mfcc, axis=1),\n",
    "        np.mean(delta, axis=1),\n",
    "        np.std(delta, axis=1),\n",
    "        np.mean(delta2, axis=1),\n",
    "        np.std(delta2, axis=1)\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "def flatten_mfcc(mfcc):\n",
    "    return np.array(mfcc).flatten()\n",
    "\n",
    "mfcc_list_heartsoundtype_mix = []\n",
    "labels_heartsoundtype_mix = []\n",
    "\n",
    "for _, row in df_heartsoundtype_mix.iterrows():\n",
    "    try:\n",
    "        mfcc_heartsoundtype = extract_mfcc(row['audio_path'])\n",
    "        # mfcc_flat = flatten_mfcc(mfcc)\n",
    "        mfcc_list_heartsoundtype_mix.append(mfcc_heartsoundtype)\n",
    "        labels_heartsoundtype_mix.append(row['Heart Sound Type'])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed: {row['audio_path']} -> {e}\")\n",
    "\n",
    "X_heartsoundtype_mix = pd.DataFrame(mfcc_list_heartsoundtype_mix)\n",
    "y_heartsoundtype_mix = pd.Series(labels_heartsoundtype_mix)\n",
    "Xtrain_heartsoundtype_mix, Xtest_heartsoundtype_mix, ytrain_heartsoundtype_mix, ytest_heartsoundtype_mix = train_test_split(X_heartsoundtype_mix, y_heartsoundtype_mix, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_heartsoundtype_mix)\n",
    "\n",
    "pipe_model_heartsoundtype_mix = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('svc', SVC(kernel='rbf', random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid_heartsoundtype_mix = {\n",
    "    'svc__C': [0.1, 1, 10, 50, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.05, 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "model_grid_heartsoundtype_mix = GridSearchCV(\n",
    "    estimator=pipe_model_heartsoundtype_mix,\n",
    "    param_grid=param_grid_heartsoundtype_mix,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model_grid_heartsoundtype_mix.fit(Xtrain_heartsoundtype_mix, ytrain_heartsoundtype_mix)\n",
    "model_heartsoundtype_mix = model_grid_heartsoundtype_mix.best_estimator_\n",
    "print(f\"Best parameters: {model_grid_heartsoundtype_mix.best_params_}\")\n",
    "ypred_heartsoundtype_mix = model_heartsoundtype_mix.predict(Xtest_heartsoundtype_mix)\n",
    "f1_heartsoundtype_mix = f1_score(ytest_heartsoundtype_mix, ypred_heartsoundtype_mix, average='macro')\n",
    "print(f\"Mix: Heart Sound Type -> macro-F1: {f1_heartsoundtype_mix}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ytest_heartsoundtype_mix, ypred_heartsoundtype_mix))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ytest_heartsoundtype_mix, ypred_heartsoundtype_mix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db40b4d",
   "metadata": {},
   "source": [
    "##### Lung Sound Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51b5deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "Mix: Lung Sound Type -> macro-F1: 0.8361416361416363\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Coarse Crackles       0.71      0.83      0.77         6\n",
      "  Fine Crackles       0.75      0.86      0.80         7\n",
      "         Normal       0.83      0.62      0.71         8\n",
      "    Pleural Rub       0.86      0.75      0.80         8\n",
      "        Rhonchi       0.88      1.00      0.93         7\n",
      "       Wheezing       1.00      1.00      1.00         8\n",
      "\n",
      "       accuracy                           0.84        44\n",
      "      macro avg       0.84      0.84      0.84        44\n",
      "   weighted avg       0.85      0.84      0.84        44\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5 1 0 0 0 0]\n",
      " [1 6 0 0 0 0]\n",
      " [1 0 5 1 1 0]\n",
      " [0 1 1 6 0 0]\n",
      " [0 0 0 0 7 0]\n",
      " [0 0 0 0 0 8]]\n"
     ]
    }
   ],
   "source": [
    "N_MFCC_LUNGSOUNDTYPE_MIX = 60\n",
    "df_lungsoundtype_mix = pd.read_csv(MIX_CSV_PATH)\n",
    "df_lungsoundtype_mix['audio_path'] = df_lungsoundtype_mix['Mixed Sound ID'].apply(lambda x: normpath(join(MIX_AUDIO_PATH, f\"{str(x).strip()}.wav\").replace('\\\\', '/')))\n",
    "def extract_mfcc_lungsoundtype_mix(filename, n_mfcc=N_MFCC_LUNGSOUNDTYPE_MIX):\n",
    "    y, sr = librosa.load(filename, sr=44100)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    return np.concatenate([mfcc_mean, mfcc_std])\n",
    "\n",
    "mfcc_list_lungsoundtype_mix = []\n",
    "labels_lungsoundtype_mix = []\n",
    "\n",
    "for _, row in df_lungsoundtype_mix.iterrows():\n",
    "    try:\n",
    "        mfcc_lungsoundtype_mix = extract_mfcc_lungsoundtype_mix(row['audio_path'])\n",
    "        # mfcc_flat = flatten_mfcc(mfcc)\n",
    "        mfcc_list_lungsoundtype_mix.append(mfcc_lungsoundtype_mix)\n",
    "        labels_lungsoundtype_mix.append(row['Lung Sound Type'])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed: {row['audio_path']} -> {e}\")\n",
    "\n",
    "X_lungsoundtype_mix = pd.DataFrame(mfcc_list_lungsoundtype_mix)\n",
    "y_lungsoundtype_mix = pd.Series(labels_lungsoundtype_mix)\n",
    "\n",
    "Xtrain_lungsoundtype_mix, Xtest_lungsoundtype_mix, ytrain_lungsoundtype_mix, ytest_lungsoundtype_mix = train_test_split(X_lungsoundtype_mix, y_lungsoundtype_mix, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_lungsoundtype_mix)\n",
    "pipe_model_lungsoundtype_mix = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(kernel='rbf', random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "param_grid_lungsoundtype_mix = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "model_grid_lungsoundtype_mix = GridSearchCV(\n",
    "    estimator=pipe_model_lungsoundtype_mix,\n",
    "    param_grid=param_grid_lungsoundtype_mix,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "model_grid_lungsoundtype_mix.fit(Xtrain_lungsoundtype_mix, ytrain_lungsoundtype_mix)\n",
    "model_lungsoundtype_mix = model_grid_lungsoundtype_mix.best_estimator_\n",
    "print(f\"Best parameters: {model_grid_lungsoundtype_mix.best_params_}\")\n",
    "ypred_lungsoundtype_mix = model_lungsoundtype_mix.predict(Xtest_lungsoundtype_mix)\n",
    "f1_lungsoundtype_mix = f1_score(ytest_lungsoundtype_mix, ypred_lungsoundtype_mix, average='macro')\n",
    "print(f\"Mix: Lung Sound Type -> macro-F1: {f1_lungsoundtype_mix}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ytest_lungsoundtype_mix, ypred_lungsoundtype_mix))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ytest_lungsoundtype_mix, ypred_lungsoundtype_mix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c339c",
   "metadata": {},
   "source": [
    "##### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "452cb951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters: {'svc__C': 100, 'svc__gamma': 0.001, 'svc__kernel': 'linear'}\n",
      "Mix: Location -> macro-F1: 0.08584239834239833\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Apex       0.00      0.00      0.00         4\n",
      "          LC       0.14      0.25      0.18         4\n",
      "         LLA       0.40      0.50      0.44         4\n",
      "        LLSB       0.11      0.25      0.15         4\n",
      "         LMA       0.00      0.00      0.00         4\n",
      "         LUA       0.00      0.00      0.00         3\n",
      "        LUSB       0.00      0.00      0.00         3\n",
      "          RC       0.00      0.00      0.00         4\n",
      "         RLA       0.25      0.25      0.25         4\n",
      "         RMA       0.00      0.00      0.00         3\n",
      "         RUA       0.00      0.00      0.00         3\n",
      "        RUSB       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.11        44\n",
      "   macro avg       0.08      0.10      0.09        44\n",
      "weighted avg       0.08      0.11      0.09        44\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0 1 0 1 1 0 0 1 0 0]\n",
      " [0 1 1 1 0 0 0 1 0 0 0 0]\n",
      " [0 1 2 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 1 1 0 0 0 0 0]\n",
      " [0 0 1 2 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 2 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 1 0 0]\n",
      " [0 2 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 1 0 0 1]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 1 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ardik\\Anaconda3\\envs\\ExamMachineLearning\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ardik\\Anaconda3\\envs\\ExamMachineLearning\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ardik\\Anaconda3\\envs\\ExamMachineLearning\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "N_MFCC_LOCATION_MIX = 2\n",
    "df_location_mix = pd.read_csv(MIX_CSV_PATH)\n",
    "df_location_mix['audio_path'] = df_location_mix['Mixed Sound ID'].apply(lambda x: normpath(join(MIX_AUDIO_PATH, f\"{str(x).strip()}.wav\").replace('\\\\', '/')))\n",
    "def extract_mfcc_location_mix(filename, n_mfcc=N_MFCC_LOCATION_MIX):\n",
    "    y, sr = librosa.load(filename, sr=166)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    return np.concatenate([mfcc_mean, mfcc_std])\n",
    "mfcc_list_location_mix = []\n",
    "labels_location_mix = []\n",
    "\n",
    "for _, row in df_location_mix.iterrows():\n",
    "    try:\n",
    "        mfcc_location_mix = extract_mfcc_location_mix(row['audio_path'])\n",
    "        # mfcc_flat = flatten_mfcc(mfcc)\n",
    "        mfcc_list_location_mix.append(mfcc_location_mix)\n",
    "        labels_location_mix.append(row['Location'])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed: {row['audio_path']} -> {e}\")\n",
    "\n",
    "X_location_mix = pd.DataFrame(mfcc_list_location_mix)\n",
    "y_location_mix = pd.Series(labels_location_mix)\n",
    "\n",
    "Xtrain_location_mix, Xtest_location_mix, ytrain_location_mix, ytest_location_mix = train_test_split(X_location_mix, y_location_mix, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_location_mix)\n",
    "pipe_model_location_mix = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(kernel='rbf', random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "param_grid_location_mix = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "model_grid_location_mix = GridSearchCV(\n",
    "    estimator=pipe_model_location_mix, \n",
    "    param_grid=param_grid_location_mix, \n",
    "    scoring='f1_macro', \n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model_grid_location_mix.fit(Xtrain_location_mix, ytrain_location_mix)\n",
    "model_location_mix = model_grid_location_mix.best_estimator_\n",
    "print(f\"Best parameters: {model_grid_location_mix.best_params_}\")\n",
    "ypred_location_mix = model_location_mix.predict(Xtest_location_mix)\n",
    "f1_location_mix = f1_score(ytest_location_mix, ypred_location_mix, average='macro')\n",
    "print(f\"Mix: Location -> macro-F1: {f1_location_mix}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ytest_location_mix, ypred_location_mix))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ytest_location_mix, ypred_location_mix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db7233",
   "metadata": {},
   "source": [
    "## LS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4398e",
   "metadata": {},
   "source": [
    "##### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa552031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters: {'svc__C': 0.1, 'svc__gamma': 0.1, 'svc__kernel': 'poly'}\n",
      "LS: Gender -> macro-F1: 0.5982142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.50      0.67      0.57         6\n",
      "           M       0.71      0.56      0.62         9\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.61      0.61      0.60        15\n",
      "weighted avg       0.63      0.60      0.60        15\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4 2]\n",
      " [4 5]]\n"
     ]
    }
   ],
   "source": [
    "N_MFCC_GENDER_LS = 58\n",
    "df_gender_ls = pd.read_csv(LS_CSV_PATH)\n",
    "df_gender_ls['audio_path'] = df_gender_ls['Lung Sound ID'].apply(lambda x: normpath(join(LS_AUDIO_PATH, f\"{str(x).strip()}.wav\").replace('\\\\', '/')))\n",
    "df_gender_ls['audio_path'] = df_gender_ls['audio_path'].str.replace('_C_', '_FC_').str.replace('_G_', '_CC_')\n",
    "def extract_mfcc_gender_ls(filename, n_mfcc=N_MFCC_GENDER_LS):\n",
    "    y, sr = librosa.load(filename, sr=44100)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    return np.concatenate([mfcc_mean, mfcc_std])\n",
    "\n",
    "def flatten_mfcc(mfcc):\n",
    "    return np.array(mfcc).flatten()\n",
    "\n",
    "mfcc_list_gender_ls = []\n",
    "labels_gender_ls = []   \n",
    "for _, row in df_gender_ls.iterrows():\n",
    "    try:\n",
    "        mfcc_gender_ls = extract_mfcc_gender_ls(row['audio_path'])\n",
    "        # mfcc_flat = flatten_mfcc(mfcc)\n",
    "        mfcc_list_gender_ls.append(mfcc_gender_ls)\n",
    "        labels_gender_ls.append(row['Gender'])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed: {row['audio_path']} -> {e}\")\n",
    "\n",
    "X_gender_ls = pd.DataFrame(mfcc_list_gender_ls)\n",
    "y_gender_ls = pd.Series(labels_gender_ls)\n",
    "\n",
    "Xtrain_gender_ls, Xtest_gender_ls, ytrain_gender_ls, ytest_gender_ls = train_test_split(X_gender_ls, y_gender_ls, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_gender_ls)\n",
    "pipe_model_gender_ls = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),   \n",
    "    ('svc', SVC(kernel='rbf', random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "]) \n",
    "\n",
    "param_grid_gender_ls = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "model_grid_gender_ls = GridSearchCV(\n",
    "    estimator=pipe_model_gender_ls,\n",
    "    param_grid=param_grid_gender_ls,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model_grid_gender_ls.fit(Xtrain_gender_ls, ytrain_gender_ls)\n",
    "model_gender_ls = model_grid_gender_ls.best_estimator_\n",
    "print(f\"Best parameters: {model_grid_gender_ls.best_params_}\")\n",
    "ypred_gender_ls = model_gender_ls.predict(Xtest_gender_ls)\n",
    "f1_gender_ls = f1_score(ytest_gender_ls, ypred_gender_ls, average='macro')\n",
    "print(f\"LS: Gender -> macro-F1: {f1_gender_ls}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ytest_gender_ls, ypred_gender_ls))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ytest_gender_ls, ypred_gender_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c56484",
   "metadata": {},
   "source": [
    "##### Lung Sound type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c254510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ardik\\Anaconda3\\envs\\ExamMachineLearning\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'svc__C': 0.1, 'svc__gamma': 0.001, 'svc__kernel': 'linear'}\n",
      "LS: Lung Sound Type -> macro-F1: 1.0\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Coarse Crackles       1.00      1.00      1.00         3\n",
      "  Fine Crackles       1.00      1.00      1.00         1\n",
      "         Normal       1.00      1.00      1.00         4\n",
      "    Pleural Rub       1.00      1.00      1.00         3\n",
      "        Rhonchi       1.00      1.00      1.00         2\n",
      "       Wheezing       1.00      1.00      1.00         2\n",
      "\n",
      "       accuracy                           1.00        15\n",
      "      macro avg       1.00      1.00      1.00        15\n",
      "   weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0 0 0 0]\n",
      " [0 1 0 0 0 0]\n",
      " [0 0 4 0 0 0]\n",
      " [0 0 0 3 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "N_MFCC_LUNGSOUNDTYPE_LS = 60\n",
    "df_lungsoundtype_ls = pd.read_csv(LS_CSV_PATH)\n",
    "df_lungsoundtype_ls['audio_path'] = df_lungsoundtype_ls['Lung Sound ID'].apply(lambda x: normpath(join(LS_AUDIO_PATH, f\"{str(x).strip()}.wav\").replace('\\\\', '/')))\n",
    "df_lungsoundtype_ls['audio_path'] = df_lungsoundtype_ls['audio_path'].str.replace('_C_', '_FC_').str.replace('_G_', '_CC_')\n",
    "def extract_mfcc_lungsoundtype_ls(filename, n_mfcc=N_MFCC_LUNGSOUNDTYPE_LS):\n",
    "    y, sr = librosa.load(filename, sr=44100)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    return np.concatenate([mfcc_mean, mfcc_std])\n",
    "\n",
    "mfcc_list_lungsoundtype_ls = []\n",
    "labels_lungsoundtype_ls = []\n",
    "\n",
    "for _, row in df_lungsoundtype_ls.iterrows():\n",
    "    try:\n",
    "        mfcc_lungsoundtype_ls = extract_mfcc_lungsoundtype_ls(row['audio_path'])\n",
    "        # mfcc_flat = flatten_mfcc(mfcc)\n",
    "        mfcc_list_lungsoundtype_ls.append(mfcc_lungsoundtype_ls)\n",
    "        labels_lungsoundtype_ls.append(row['Lung Sound Type'])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed: {row['audio_path']} -> {e}\")\n",
    "\n",
    "X_lungsoundtype_ls = pd.DataFrame(mfcc_list_lungsoundtype_ls)\n",
    "y_lungsoundtype_ls = pd.Series(labels_lungsoundtype_ls)\n",
    "\n",
    "Xtrain_lungsoundtype_ls, Xtest_lungsoundtype_ls, ytrain_lungsoundtype_ls, ytest_lungsoundtype_ls = train_test_split(X_lungsoundtype_ls, y_lungsoundtype_ls, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_lungsoundtype_ls)\n",
    "pipe_model_lungsoundtype_ls = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(kernel='rbf', random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "param_grid_lungsoundtype_ls = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "model_grid_lungsoundtype_ls = GridSearchCV(\n",
    "    estimator=pipe_model_lungsoundtype_ls,\n",
    "    param_grid=param_grid_lungsoundtype_ls,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "model_grid_lungsoundtype_ls.fit(Xtrain_lungsoundtype_ls, ytrain_lungsoundtype_ls)\n",
    "model_lungsoundtype_ls = model_grid_lungsoundtype_ls.best_estimator_\n",
    "print(f\"Best parameters: {model_grid_lungsoundtype_ls.best_params_}\")\n",
    "ypred_lungsoundtype_ls = model_lungsoundtype_ls.predict(Xtest_lungsoundtype_ls)\n",
    "f1_lungsoundtype_ls = f1_score(ytest_lungsoundtype_ls, ypred_lungsoundtype_ls, average='macro')\n",
    "print(f\"LS: Lung Sound Type -> macro-F1: {f1_lungsoundtype_ls}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ytest_lungsoundtype_ls, ypred_lungsoundtype_ls))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ytest_lungsoundtype_ls, ypred_lungsoundtype_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e9d32",
   "metadata": {},
   "source": [
    "##### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a10b75a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ardik\\Anaconda3\\envs\\ExamMachineLearning\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'svc__C': 10, 'svc__gamma': 0.01, 'svc__kernel': 'poly'}\n",
      "LS: Location -> macro-F1: 0.3674603174603175\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LLA       0.25      0.50      0.33         2\n",
      "         LMA       0.50      0.67      0.57         3\n",
      "         LUA       1.00      0.67      0.80         3\n",
      "         RLA       1.00      0.33      0.50         3\n",
      "         RMA       0.00      0.00      0.00         2\n",
      "         RUA       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.40        15\n",
      "   macro avg       0.46      0.36      0.37        15\n",
      "weighted avg       0.53      0.40      0.42        15\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1 0 0 0 0 1]\n",
      " [0 2 0 0 1 0]\n",
      " [1 0 2 0 0 0]\n",
      " [2 0 0 1 0 0]\n",
      " [0 1 0 0 0 1]\n",
      " [0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "N_MFCC_LOCATION_LS = 60\n",
    "df_location_ls = pd.read_csv(LS_CSV_PATH)\n",
    "df_location_ls['audio_path'] = df_location_ls['Lung Sound ID'].apply(lambda x: normpath(join(LS_AUDIO_PATH, f\"{str(x).strip()}.wav\").replace('\\\\', '/')))\n",
    "df_location_ls['audio_path'] = df_location_ls['audio_path'].str.replace('_C_', '_FC_').str.replace('_G_', '_CC_')\n",
    "def extract_mfcc_location_ls(filename, n_mfcc=N_MFCC_LOCATION_LS):\n",
    "    y, sr = librosa.load(filename, sr=70000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "    return np.concatenate([mfcc_mean, mfcc_std])\n",
    "mfcc_list_location_ls = []\n",
    "labels_location_ls = []\n",
    "for _, row in df_location_ls.iterrows():\n",
    "    try:\n",
    "        mfcc_location_ls = extract_mfcc_location_ls(row['audio_path'])\n",
    "        # mfcc_flat = flatten_mfcc(mfcc)\n",
    "        mfcc_list_location_ls.append(mfcc_location_ls)\n",
    "        labels_location_ls.append(row['Location'])\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed: {row['audio_path']} -> {e}\")\n",
    "\n",
    "X_location_ls = pd.DataFrame(mfcc_list_location_ls)\n",
    "y_location_ls = pd.Series(labels_location_ls)\n",
    "Xtrain_location_ls, Xtest_location_ls, ytrain_location_ls, ytest_location_ls = train_test_split(X_location_ls, y_location_ls, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_location_ls)\n",
    "pipe_model_location_ls = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(kernel='rbf', random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "param_grid_location_ls = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'svc__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "model_grid_location_ls = GridSearchCV(\n",
    "    estimator=pipe_model_location_ls,\n",
    "    param_grid=param_grid_location_ls,\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "model_grid_location_ls.fit(Xtrain_location_ls, ytrain_location_ls)\n",
    "model_location_ls = model_grid_location_ls.best_estimator_\n",
    "print(f\"Best parameters: {model_grid_location_ls.best_params_}\")\n",
    "ypred_location_ls = model_location_ls.predict(Xtest_location_ls)\n",
    "f1_location_ls = f1_score(ytest_location_ls, ypred_location_ls, average='macro')\n",
    "print(f\"LS: Location -> macro-F1: {f1_location_ls}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ytest_location_ls, ypred_location_ls))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(ytest_location_ls, ypred_location_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e342e",
   "metadata": {},
   "source": [
    "Sumber AI : \n",
    "https://github.com/copilot/share/80665316-4184-8822-8812-a447a02f48e9\n",
    "https://chatgpt.com/share/696cfe0c-cf00-800e-9ce4-f71726a7d39b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExamMachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
